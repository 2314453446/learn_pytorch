{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62996/3334078019.py:2: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1405.)\n",
      "  _ =torch.tensor([0.2126,0.7152,0.0722],names=['c'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "_ =torch.tensor([0.2126,0.7152,0.0722],names=['c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "img_t =torch.randn(3,5,5)\n",
    "weight = torch.tensor([0.2126,0.7152,0.0722])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2,3,5,5) #shape [batch,channels,rows,columns]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 5])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)#在倒数第三个维度取平均\n",
    "img_gray_naive.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 5, 5])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_naive = batch_t.mean(-3)\n",
    "batch_gray_naive.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0.2126],\n         [0.7152],\n         [0.0722]]),\n torch.Size([3, 1]))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.tensor([0.2126,0.7152,0.0722])\n",
    "unsqueenzed_weight = torch.unsqueeze(weight,-1)\n",
    "unsqueenzed_weight,unsqueenzed_weight.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.2126]],\n \n         [[0.7152]],\n \n         [[0.0722]]]),\n torch.Size([3, 1, 1]))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueenzed_weight=unsqueenzed_weight.unsqueeze(-1)\n",
    "unsqueenzed_weight,unsqueenzed_weight.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 5, 5])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_weights = (img_t*unsqueenzed_weight)\n",
    "img_weights.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 5, 5])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_weight = (batch_t*unsqueenzed_weight)\n",
    "batch_weight.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "img_gray_naive=img_weights.sum(-3)\n",
    "batch_gray_naive = batch_weight.sum(-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 5, 5])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_gray_naive.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2126, 0.7152, 0.0772], names=('channels',))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126,0.7152,0.0772],names=['channels'])\n",
    "weights_named"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "img_named = img_t.refine_names(...,'channels','rows','columns')\n",
    "batch_named = batch_t.refine_names(...,'channels','rows','columns')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-1.1868, -0.2110, -1.2946,  1.0491, -0.8014],\n         [ 1.5754,  0.3107, -0.7649,  0.1765,  0.1869],\n         [-1.3954,  0.7558, -2.3620, -1.3611, -0.7640],\n         [ 1.2083,  0.9279,  0.2932, -1.0009, -0.6761],\n         [-2.2376, -0.6900,  1.3789,  1.0597, -0.0886]],\n\n        [[ 2.2504,  0.6935, -1.2463,  0.9669, -1.5942],\n         [ 1.0237, -1.7382, -1.4945, -0.3176,  0.8943],\n         [-0.7552, -0.0377, -1.2089,  1.1951,  1.3552],\n         [ 0.2170,  0.1713, -0.0129,  0.1930,  1.2792],\n         [ 1.4446, -1.5114,  0.8920,  0.2609,  0.3935]],\n\n        [[ 0.9918,  0.6454, -1.1049,  0.9195,  1.7985],\n         [ 0.7770,  0.2752, -0.4337, -0.4617,  0.1066],\n         [-0.6843, -0.0156, -1.0379, -0.9116,  0.6958],\n         [-0.2380, -0.6309,  0.0138,  0.2736, -0.7238],\n         [ 0.6087,  0.8988,  0.8158, -0.3998, -0.9962]]],\n       names=('channels', 'rows', 'columns'))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_named"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1.2248,  0.8224,  0.6409,  0.4427,  0.8285],\n          [-0.2669, -2.3206, -0.7529, -0.9412, -1.1082],\n          [ 1.3834, -0.7048,  0.7889,  1.0401,  0.8188],\n          [-0.2065, -1.2813,  0.4173,  0.0271,  0.0230],\n          [ 0.0814,  0.8336,  1.2084,  0.8525, -0.3822]],\n\n         [[-1.3112, -0.2034,  1.3620,  0.2977, -1.6385],\n          [-0.5816, -0.9671, -0.3820,  1.1767,  0.1871],\n          [ 0.7911, -0.6904,  0.3583, -0.1199, -0.9026],\n          [ 0.7997, -0.6620, -0.3076, -1.2689, -0.3593],\n          [ 0.6963,  1.2549,  0.8879,  1.1922,  0.1766]],\n\n         [[-0.6096, -0.9504, -2.3129,  0.3664,  0.8728],\n          [-0.7889,  0.3114,  0.5534,  0.3326, -0.2005],\n          [ 0.3673,  0.3758,  0.6248, -0.5756,  0.6163],\n          [ 0.1624, -0.9273,  0.4795, -0.3754, -1.0836],\n          [ 0.0809,  0.5413, -1.2631,  0.8946, -1.6769]]],\n\n\n        [[[-1.9255, -2.2112,  1.3936,  0.1995,  0.7272],\n          [ 0.0946, -1.6523,  1.2014, -0.2640,  0.5113],\n          [ 0.6448, -1.1842, -0.2071, -0.7633,  0.0583],\n          [-0.6649, -0.3520,  1.1019,  0.7982,  0.7744],\n          [ 1.4803,  0.6164,  1.1973,  1.6059,  2.9322]],\n\n         [[ 1.0985,  0.6633,  0.7664,  0.0999,  0.3327],\n          [ 0.5593, -1.1399, -0.6493,  0.4264,  0.6426],\n          [-1.3508, -0.8506,  0.4746,  0.3144, -0.6640],\n          [-0.6594, -0.7042, -0.6512,  1.4411, -0.1749],\n          [ 0.1432,  0.9551, -0.8372,  1.5185,  0.7899]],\n\n         [[ 0.7879, -0.4530,  0.2901, -0.1553,  1.1942],\n          [-0.5602, -0.6706,  1.3412,  0.5505,  0.5184],\n          [ 0.4450,  2.1136,  0.1666,  0.2263,  0.2847],\n          [-1.4479, -0.1566,  0.1054,  1.0020,  0.9615],\n          [ 0.7747, -0.4906,  1.0314, -0.5222,  0.4660]]]],\n       names=(None, 'channels', 'rows', 'columns'))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_named"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(('channels',), (None, 'channels', 'rows', 'columns'))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named.names,batch_named.names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[0.2126]],\n \n         [[0.7152]],\n \n         [[0.0772]]], names=('channels', 'rows', 'columns')),\n ('channels',),\n torch.Size([3, 1, 1]))"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#张量对齐\n",
    "weight_alighted = weights_named.align_as(img_named)\n",
    "weight_alighted,weights_named.names,weight_alighted.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 1.4338,  0.5010, -1.2519,  0.9855, -1.1717],\n         [ 1.1270, -1.1558, -1.2650, -0.2253,  0.6876],\n         [-0.8896,  0.1325, -1.4469,  0.4950,  0.8605],\n         [ 0.3937,  0.2711,  0.0542, -0.0537,  0.7153],\n         [ 0.6045, -1.1583,  0.9941,  0.3810,  0.1857]],\n        names=('rows', 'columns')),\n torch.Size([5, 5]),\n ('rows', 'columns'),\n tensor([[[-1.1868, -0.2110, -1.2946,  1.0491, -0.8014],\n          [ 1.5754,  0.3107, -0.7649,  0.1765,  0.1869],\n          [-1.3954,  0.7558, -2.3620, -1.3611, -0.7640],\n          [ 1.2083,  0.9279,  0.2932, -1.0009, -0.6761],\n          [-2.2376, -0.6900,  1.3789,  1.0597, -0.0886]],\n \n         [[ 2.2504,  0.6935, -1.2463,  0.9669, -1.5942],\n          [ 1.0237, -1.7382, -1.4945, -0.3176,  0.8943],\n          [-0.7552, -0.0377, -1.2089,  1.1951,  1.3552],\n          [ 0.2170,  0.1713, -0.0129,  0.1930,  1.2792],\n          [ 1.4446, -1.5114,  0.8920,  0.2609,  0.3935]],\n \n         [[ 0.9918,  0.6454, -1.1049,  0.9195,  1.7985],\n          [ 0.7770,  0.2752, -0.4337, -0.4617,  0.1066],\n          [-0.6843, -0.0156, -1.0379, -0.9116,  0.6958],\n          [-0.2380, -0.6309,  0.0138,  0.2736, -0.7238],\n          [ 0.6087,  0.8988,  0.8158, -0.3998, -0.9962]]],\n        names=('channels', 'rows', 'columns')))"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named*weight_alighted).sum('channels')\n",
    "gray_named,gray_named.shape,gray_named.names,img_named"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
